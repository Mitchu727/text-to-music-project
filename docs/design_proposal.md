# Design proposal

## Functionality
Generating audio samples conditioned on descriptive text captions 
 - We want to create simple app that would give the user possibility to generate music based on text with different models and parameters 
 - Frontend for non-programming users 
 - Simple API that would give the user ability to generate music using different models 
 - Implementing metrics calculations for generated audio 
 - We strive for scalable architecture in which addition of new models or modalities should be easy 

## Technology stack

 * Gradio 
 * Python 
    - Librosa 
    - Pytest 
    - Pylint/flake8 
    - Pytorch/tensorflow 
    - Black 
    - venv 
* Github actions 
## Experiments
 * With the use of our framework, we want to do the following: 
    - Subjective comparison of the music generated by different models with the same prompt 
    - Check in which types of music specific models are good 
    - Check how metrics behave in different models for the same prompt 
    - Check how model behaves depending on prompt 

## Project roadmap
| Week | Milestones |
|---|---|
| 11.03.2024 - 17.03.2024 | project setup |
| 18.03.2024 - 24.03.2024  | research of papers |
| 25.03.2024 - 31.03.2024  | simple implementation of one model |
| 01.04.2024 - 07.04.2024  | gradio app |
| 08.04.2024 - 14.04.2024  | metrics implementation |
| 15.03.2024 - 21.04.2024  | implementation of second model |
| 22.03.2024 - 28.04.2024  | user oriented experiments |
| 29.03.2024 - 05.05.2024  | architecture overview (looking for design patterns that could be used) |
| 06.05.2024 - 12.05.2024  | implementation of other models |
| 13.05.2024 - 19.05.2024  | experiments |
| 20.05.2024 - 26.05.2024  | code refactoring |
| 27.05.2024 - 02.06.2024  | deployment setup |
| 03.06.2024 - 09.06.2024  | documentation |
| 10.06.2024 - 16.06.2024  | finishing, last touches, buffer for vis maior |

## References




